{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F  \n",
    "import torchvision.datasets as datasets  \n",
    "import torchvision.transforms as transforms  \n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "experiment = \"CIFAR10\"\n",
    "# Load Data\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./CIFAR10\", train = True, download = True, transform = data_transforms[\"train\"])\n",
    "test_set = torchvision.datasets.CIFAR10(root=\"./CIFAR10\", train = False, download = True, transform = data_transforms[\"test\"])\n",
    "train_size = len(train_set)\n",
    "test_size = len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10\n",
      "Number of batches: 3125\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_workers = 1\n",
    "classes = train_set.classes\n",
    "num_class = len(classes)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "num_batches = math.floor(train_size/batch_size)\n",
    "print(f\"Number of classes: {num_class}\")\n",
    "print(f\"Number of batches: {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\dongt/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "C:\\Users\\dongt/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  \"pytorch_quantization module not found, quantization will not be available\"\n",
      "C:\\Users\\dongt/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  \"pytorch_quantization module not found, quantization will not be available\"\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_widese_b0', pretrained=True)\n",
    "in_fc = model.classifier.fc.in_features\n",
    "model.classifier.fc = nn.Linear(in_fc, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a2f8ffd140407e9b02532bfaa3a00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?epochs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bf8f30826a4b79b3374f9848827224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/3125 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154e9b5b516a4ad088efdad66366fd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Initialize network\n",
    "model.to(device)\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "writer = SummaryWriter(f\"runs/{experiment}/BatchSize {batch_size} LR {learning_rate}\")\n",
    "\n",
    "# Inspect the model\n",
    "images, _ = next(iter(train_loader))\n",
    "writer.add_graph(model, images.to(device))\n",
    "writer.close()\n",
    "\n",
    "# Progress bar\n",
    "outer = tqdm(total=num_epochs, unit=\"epochs\", position=0, desc=\"Epoch\")\n",
    "inner = tqdm(total=num_batches, unit=\"batches\", position=1, desc=\"Batch\")\n",
    "batch_log = tqdm(total=0, position=3, bar_format='{desc}')\n",
    "\n",
    "# Train\n",
    "epoch_dict = {}\n",
    "step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)                          # N, C, W, H\n",
    "        labels = labels.to(device)                          # N\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predictions = outputs.max(1)                     # N\n",
    "        step_accuracy = (predictions == labels).sum() / inputs.shape[0]\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        \n",
    "        # update dict at end epoch\n",
    "        if batch_idx == num_batches - 1:\n",
    "            epoch_dict[epoch] = {\"loss\": round(loss.item(), 4),\n",
    "                                 \"accuracy\": round(step_accuracy.item(), 4)}\n",
    "            \n",
    "        # TensorBoard\n",
    "        writer.add_histogram(\"Classifier layer parameter\", model.classifier.fc.weight)\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        writer.add_scalar(\"Training Accuracy\", step_accuracy, global_step=step)\n",
    "        \n",
    "        # update progression bar\n",
    "        batch_log.set_description_str(f\"loss: {round(loss.item(), 4)}, accuracy: {step_accuracy}\")\n",
    "        inner.update(1)\n",
    "    outer.update(1)\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.3373 accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "for i in epoch_dict:\n",
    "    print(f\"Epoch {i + 1} - Loss:\", epoch_dict[i][\"loss\"], \"accuracy:\", epoch_dict[i][\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "params_path = \"./model/model_params\"\n",
    "torch.save(model.state_dict(), params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for validation\n",
    "params_path = \"./model/model_params\"\n",
    "# Model\n",
    "model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_widese_b0', pretrained=True)\n",
    "in_fc = model.classifier.fc.in_features\n",
    "model.classifier.fc = nn.Linear(in_fc, num_class)\n",
    "model.load_state_dict(torch.load(params_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be203ce0b3afc4f5c37fbac412025d7ed1d67cabe9dd00b1fc8774c6d6d19d70"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
